# Instrucciones para Subir el Proyecto a GitHub

## ğŸ“‹ Pasos para Subir al Repositorio

### 1. Navegar a la carpeta del proyecto
```bash
cd C:\Users\Cris\Desktop\kafka-clima-lima-local
```

### 2. Inicializar repositorio Git (si no estÃ¡ inicializado)
```bash
git init
```

### 3. Configurar el repositorio remoto
```bash
git remote add origin https://github.com/CristianRamosMedina/BIG-DATA-Kafka.git
```

**Si ya existe el remote, actualÃ­zalo:**
```bash
git remote set-url origin https://github.com/CristianRamosMedina/BIG-DATA-Kafka.git
```

### 4. Crear la rama principal (si es necesario)
```bash
git branch -M main
```

### 5. Agregar todos los archivos
```bash
git add .
```

**Esto agregarÃ¡:**
- âœ… CÃ³digo fuente (producers/, consumers/, dashboard/)
- âœ… Docker compose
- âœ… README.md
- âœ… .gitignore
- âœ… Script de timestamps
- âŒ Archivos JSON generados (ignorados por .gitignore)

### 6. Verificar los archivos a subir
```bash
git status
```

**DeberÃ­as ver archivos como:**
```
modified:   README.md
new file:   .gitignore
new file:   producers/producer_realtime.py
new file:   producers/producer_cleaning.py
new file:   consumers/consumer_batch.py
new file:   consumers/consumer_alerts.py
new file:   consumers/consumer_predictor_lluvia.py
new file:   consumers/consumer_predictor_sol.py
new file:   consumers/consumer_clasificador_clima.py
new file:   consumers/consumer_predicciones_consolidadas.py
new file:   dashboard/app.py
new file:   docker-compose.yml
new file:   agregar_timestamps.py
new file:   data/batch/.gitkeep
new file:   data/alerts/.gitkeep
new file:   data/predictions/.gitkeep
```

### 7. Hacer commit
```bash
git commit -m "Sistema completo de monitoreo climatico con Kafka

- Implementacion de 2 producers (realtime y cleaning)
- Implementacion de 6 consumers (batch, alerts, 3 predictores, consolidador)
- Dashboard web con Streamlit (auto-refresh cada 30s)
- 3 modelos de prediccion climatica basados en reglas
- Sistema de procesamiento batch cada 2 minutos
- Registros con timestamps para analisis temporal
- Predicciones por zona con visualizacion de emojis
- Arquitectura completa con 4 topics de Kafka
- Docker Compose para Kafka + Zookeeper"
```

### 8. Subir a GitHub
```bash
git push -u origin main
```

**Si el repositorio ya existe y hay conflictos:**
```bash
git pull origin main --rebase
git push -u origin main
```

**Si quieres forzar el push (âš ï¸ CUIDADO: sobrescribirÃ¡ el contenido remoto):**
```bash
git push -u origin main --force
```

---

## ğŸ” Verificar que se subiÃ³ correctamente

1. Ve a: https://github.com/CristianRamosMedina/BIG-DATA-Kafka
2. Verifica que aparezcan:
   - âœ… README.md formateado correctamente
   - âœ… Carpetas: producers/, consumers/, dashboard/, data/
   - âœ… Archivo docker-compose.yml
   - âœ… .gitignore
   - âŒ NO deben aparecer archivos .json en data/

---

## ğŸ“ Estructura Final en GitHub

```
BIG-DATA-Kafka/
â”œâ”€â”€ README.md                              â­ DocumentaciÃ³n completa
â”œâ”€â”€ .gitignore                            ğŸš« Archivos ignorados
â”œâ”€â”€ docker-compose.yml                    ğŸ³ Config de Kafka
â”œâ”€â”€ agregar_timestamps.py                 ğŸ”§ Utilidad
â”‚
â”œâ”€â”€ producers/
â”‚   â”œâ”€â”€ producer_realtime.py
â”‚   â””â”€â”€ producer_cleaning.py
â”‚
â”œâ”€â”€ consumers/
â”‚   â”œâ”€â”€ consumer_batch.py
â”‚   â”œâ”€â”€ consumer_alerts.py
â”‚   â”œâ”€â”€ consumer_predictor_lluvia.py
â”‚   â”œâ”€â”€ consumer_predictor_sol.py
â”‚   â”œâ”€â”€ consumer_clasificador_clima.py
â”‚   â””â”€â”€ consumer_predicciones_consolidadas.py
â”‚
â”œâ”€â”€ dashboard/
â”‚   â””â”€â”€ app.py
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ batch/.gitkeep                    ğŸ“‚ Carpeta vacÃ­a
    â”œâ”€â”€ alerts/.gitkeep                   ğŸ“‚ Carpeta vacÃ­a
    â””â”€â”€ predictions/.gitkeep              ğŸ“‚ Carpeta vacÃ­a
```

---

## âš™ï¸ Comandos Ãštiles Adicionales

### Ver el historial de commits
```bash
git log --oneline
```

### Ver archivos ignorados
```bash
git status --ignored
```

### Crear una nueva rama (opcional)
```bash
git checkout -b feature/nueva-funcionalidad
```

### Ver diferencias antes de commit
```bash
git diff
```

### Deshacer cambios no guardados
```bash
git restore <archivo>
```

### Remover archivo del staging
```bash
git reset HEAD <archivo>
```

---

## ğŸ“ Para la Clase de CCOMP

### Puntos a Destacar en la PresentaciÃ³n:

1. **Arquitectura Kafka:**
   - 1 Broker
   - 4 Topics
   - 2 Producers
   - 6 Consumers
   - 6 Consumer Groups diferentes

2. **Flujo de Datos:**
   - API Real â†’ Producer â†’ Topic Raw â†’ Producer Cleaning â†’ Topic Clean â†’ 6 Consumers â†’ Archivos JSON â†’ Dashboard

3. **Procesamiento:**
   - Tiempo Real: Cada 10 segundos
   - Batch: Cada ~2 minutos (72 mensajes)
   - Predicciones: 3 modelos en paralelo

4. **VisualizaciÃ³n:**
   - Dashboard interactivo
   - Auto-refresh automÃ¡tico
   - Predicciones con emojis
   - Mapas y grÃ¡ficos

5. **Escalabilidad:**
   - FÃ¡cil agregar mÃ¡s zonas
   - FÃ¡cil agregar mÃ¡s consumers
   - Modular y extensible

---

## ğŸ“ Notas Importantes

- **NO se suben archivos .json** (estÃ¡n en .gitignore)
- **SÃ se suben las carpetas vacÃ­as** (con .gitkeep)
- **El README tiene toda la documentaciÃ³n** necesaria
- **Sin nombres de AI** en el cÃ³digo ni commits
- **Proyecto 100% funcional** y documentado

---

## âœ… Checklist Final

Antes de presentar, verifica:

- [ ] README.md completo y actualizado
- [ ] Todos los archivos .py estÃ¡n comentados
- [ ] docker-compose.yml funciona
- [ ] .gitignore configurado correctamente
- [ ] No hay archivos temporales o datos sensibles
- [ ] El dashboard corre en localhost:8501
- [ ] Todos los consumers funcionan
- [ ] Las predicciones se generan correctamente
- [ ] El repositorio estÃ¡ pÃºblico (o privado segÃºn requieran)
- [ ] No hay menciones a herramientas de IA en el cÃ³digo

---

## ğŸ‰ Â¡Listo!

Tu proyecto estÃ¡ completo y listo para:
- PresentaciÃ³n en clase
- RevisiÃ³n del profesor
- Portfolio personal
- PrÃ¡ctica de Kafka

**Repositorio:** https://github.com/CristianRamosMedina/BIG-DATA-Kafka
